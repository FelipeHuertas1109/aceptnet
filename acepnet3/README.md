# Pipeline de Entrenamiento de AFD Dual-Encoder

Este proyecto estÃ¡ dividido en dos scripts independientes para optimizar el flujo de trabajo:

## ğŸ“‚ Archivos

1. **`gen_dataset_exhaustive.py`** - GeneraciÃ³n de dataset (CPU)
2. **`train_dual_encoder.py`** - Entrenamiento del modelo (GPU)
3. **`dataset6000.csv`** - Dataset original de AFDs
4. **`acepten_colab.py`** - Script original (referencia)

---

## ğŸ”„ Flujo de Trabajo

### Paso 1: Generar Dataset (Una sola vez)

Este script genera todas las cadenas exhaustivamente y crea el dataset completo.

**CaracterÃ­sticas:**
- âœ… Solo CPU (no necesita GPU)
- âœ… Se ejecuta una sola vez (o cuando cambias la lÃ³gica)
- âœ… Genera ~1.5M ejemplos en pocos minutos
- âœ… 100% preciso: cada etiqueta verificada por simulaciÃ³n

**EjecuciÃ³n en Google Colab:**

```python
# 1. Sube dataset6000.csv a /content/sample_data/
# 2. Sube gen_dataset_exhaustive.py a /content/
# 3. Ejecuta
!python gen_dataset_exhaustive.py
```

**EjecuciÃ³n Local:**

```bash
# En tu PC local
cd acepnet3
python gen_dataset_exhaustive.py
```

**Salida:**
- `dataset_generated.csv` â†’ Dataset completo con columnas: `dfa_id`, `string`, `label`, `y2`

**ConfiguraciÃ³n (en el archivo):**
```python
GEN_CONFIG = {
    'pos_samples_per_dfa': 100,  # MÃ¡ximo de positivos
    'neg_samples_per_dfa': 150,  # MÃ¡ximo de negativos
    'max_string_length': 5,      # Longitud mÃ¡xima
}
```

---

### Paso 2: Entrenar Modelo (Repetir cuando quieras)

Este script entrena el modelo usando el dataset ya generado.

**CaracterÃ­sticas:**
- âœ… Optimizado para GPU (T4 en Colab)
- âœ… Se puede ejecutar mÃºltiples veces
- âœ… RÃ¡pido: ~5-10 min en T4
- âœ… Early stopping automÃ¡tico

**EjecuciÃ³n en Google Colab:**

```python
# 1. Sube estos archivos a /content/sample_data/
#    - dataset6000.csv
#    - dataset_generated.csv

# 2. Sube train_dual_encoder.py a /content/

# 3. Ejecuta
!python train_dual_encoder.py
```

**EjecuciÃ³n Local (si tienes GPU):**

```bash
cd acepnet3
python train_dual_encoder.py
```

**Salidas:**
- `best_model.pt` â†’ Modelo entrenado
- `thresholds.json` â†’ Umbrales calibrados
- `training_history.png` â†’ GrÃ¡ficas de entrenamiento

**ConfiguraciÃ³n (en el archivo):**
```python
TRAIN_CONFIG = {
    'label_smoothing': 0.0,      # Sin smoothing
    'lambda1': 1.0,              # Peso de Y1
    'lambda2': 0.3,              # Peso de Y2
    'batch_size': 128,
    'num_epochs': 40,            # MÃ¡ximo
    'early_stop_patience': 7,    # Ã‰pocas sin mejora
    'early_stop_min_delta': 1e-4 # Mejora mÃ­nima
}
```

---

## ğŸ¯ IntegraciÃ³n con Django Backend

Una vez entrenado, copia estos archivos a tu backend:

```
C:\Users\Felipe Huertas\Documents\Codigos\lenguajes-back\models\acepnet\
â”œâ”€â”€ dataset6000.csv        â† Para reconstruir AFDs
â”œâ”€â”€ best_model.pt          â† Modelo entrenado
â””â”€â”€ thresholds.json        â† Umbrales calibrados
```

Tu servicio Django (`acepnet_service.py`) solo necesita:
1. Cargar `dataset6000.csv` para obtener features de AFDs
2. Cargar `best_model.pt` para inferencia
3. Cargar `thresholds.json` para clasificaciÃ³n

---

## ğŸ“Š Ventajas de esta SeparaciÃ³n

| Aspecto | Antes | Ahora |
|---------|-------|-------|
| **GeneraciÃ³n** | Cada entrenamiento | Una sola vez |
| **GPU para generaciÃ³n** | Desperdiciada | No se usa (CPU) |
| **ExperimentaciÃ³n** | Lenta | RÃ¡pida |
| **Reproducibilidad** | DifÃ­cil | FÃ¡cil (mismo CSV) |

---

## ğŸ”§ Modificar ConfiguraciÃ³n

### Para cambiar el tamaÃ±o del dataset:

Edita `gen_dataset_exhaustive.py`:
```python
GEN_CONFIG = {
    'pos_samples_per_dfa': 150,  # MÃ¡s positivos
    'neg_samples_per_dfa': 200,  # MÃ¡s negativos
    'max_string_length': 6,      # Cadenas mÃ¡s largas
}
```

Luego regenera el dataset:
```bash
python gen_dataset_exhaustive.py
```

### Para cambiar hiperparÃ¡metros de entrenamiento:

Edita `train_dual_encoder.py`:
```python
TRAIN_CONFIG = {
    'lambda1': 1.5,              # Mayor peso a Y1
    'lambda2': 0.2,              # Menor peso a Y2
    'batch_size': 256,           # Batch mÃ¡s grande (si tienes memoria)
    'num_epochs': 50,            # MÃ¡s Ã©pocas
    'early_stop_patience': 10,   # MÃ¡s paciencia
}
```

---

## ğŸš€ Ejemplo Completo (Colab)

### OpciÃ³n A: Generar dataset EN Colab (recomendado si no lo tienes)

```python
# ===== CELDA 1: Subir archivos =====
from google.colab import files

print("ğŸ“¤ Sube dataset6000.csv")
uploaded = files.upload()

print("ğŸ“¤ Sube gen_dataset_exhaustive.py")
uploaded = files.upload()

print("ğŸ“¤ Sube train_dual_encoder.py")
uploaded = files.upload()

# Mover a /content/sample_data/
!mkdir -p /content/sample_data
!mv dataset6000.csv /content/sample_data/

# ===== CELDA 2: Generar dataset (CPU) =====
!python gen_dataset_exhaustive.py

# Mover dataset generado a sample_data
!mv dataset_generated.csv /content/sample_data/

# ===== CELDA 3: Entrenar (GPU) =====
!python train_dual_encoder.py

# ===== CELDA 4: Descargar resultados =====
files.download('best_model.pt')
files.download('thresholds.json')
files.download('training_history.png')
```

### OpciÃ³n B: Solo entrenar (si ya tienes dataset_generated.csv)

```python
# ===== CELDA 1: Subir archivos =====
from google.colab import files

print("ğŸ“¤ Sube dataset6000.csv")
uploaded = files.upload()

print("ğŸ“¤ Sube dataset_generated.csv")
uploaded = files.upload()

print("ğŸ“¤ Sube train_dual_encoder.py")
uploaded = files.upload()

# Mover a /content/sample_data/
!mkdir -p /content/sample_data
!mv dataset6000.csv /content/sample_data/
!mv dataset_generated.csv /content/sample_data/

# ===== CELDA 2: Entrenar =====
!python train_dual_encoder.py

# ===== CELDA 3: Descargar resultados =====
files.download('best_model.pt')
files.download('thresholds.json')
files.download('training_history.png')
```

---

## â“ FAQ

**P: Â¿Tengo que regenerar el dataset cada vez?**  
R: No, solo cuando cambies la configuraciÃ³n de generaciÃ³n o el dataset de AFDs.

**P: Â¿Puedo entrenar sin GPU?**  
R: SÃ­, pero serÃ¡ mucho mÃ¡s lento (~1-2 horas vs 5-10 minutos en T4).

**P: Â¿El dataset generado es diferente cada vez?**  
R: Las cadenas son exhaustivas, pero el orden es aleatorio. Los resultados son equivalentes.

**P: Â¿CÃ³mo sÃ© si el modelo estÃ¡ bien entrenado?**  
R: Busca en la salida:
- Y1 Accuracy > 0.95
- Y1 F1 Score > 0.95
- Y2 PR-AUC > 0.80

**P: Â¿Puedo usar este pipeline en producciÃ³n?**  
R: SÃ­, solo necesitas los 3 archivos de salida:
  - `dataset6000.csv`
  - `best_model.pt`
  - `thresholds.json`

---

## ğŸ“ Notas

- El script de generaciÃ³n usa `tqdm` para mostrar progreso
- El script de entrenamiento usa early stopping para evitar overfitting
- Ambos scripts tienen manejo de errores para rutas de archivos
- Los scripts son compatibles con Windows, Linux y macOS

