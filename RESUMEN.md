# ğŸ‰ Resumen del Proyecto - Modelo Dual-Encoder para AFDs

## ğŸ“ Archivos Creados

### ğŸ–¥ï¸ Para Uso Local (CPU)
- **`acepten.py`** - Script completo para entrenar localmente (769 lÃ­neas)
- **`test_pipeline.py`** - Script de pruebas rÃ¡pidas
- **`requirements.txt`** - Dependencias del proyecto

### â˜ï¸ Para Google Colab (GPU) â­ RECOMENDADO
- **`acepten_colab.py`** - Script optimizado para Colab con GPU (650 lÃ­neas)
  - âœ… Barras de progreso con tqdm
  - âœ… Batch size optimizado para GPU (128)
  - âœ… DetecciÃ³n automÃ¡tica de CUDA
  - âœ… Rutas configuradas para `/content/sample_data/`

### ğŸ“š DocumentaciÃ³n
- **`README.md`** - DocumentaciÃ³n completa del proyecto
- **`COLAB_INSTRUCTIONS.md`** - GuÃ­a paso a paso para Colab
- **`quick_colab_setup.txt`** - Setup super rÃ¡pido (copiar/pegar)

### ğŸ“Š Dataset
- **`dataset6000.csv`** - 6000 AFDs originales (ya tienes)

---

## ğŸš€ QUICK START - Google Colab (Recomendado)

### 1ï¸âƒ£ Abrir Google Colab
- Ve a: https://colab.research.google.com/
- Crea un nuevo notebook
- **Activar GPU**: `Runtime` â†’ `Change runtime type` â†’ **GPU**

### 2ï¸âƒ£ Celda 1: Setup
```python
# Instalar dependencias
!pip install -q torch pandas numpy scikit-learn matplotlib tqdm

# Subir archivos
from google.colab import files
import shutil

print("ğŸ“¤ Sube dataset6000.csv:")
uploaded = files.upload()
!mkdir -p /content/sample_data
shutil.move('dataset6000.csv', '/content/sample_data/dataset6000.csv')

print("\nğŸ“¤ Sube acepten_colab.py:")
uploaded = files.upload()

# Verificar GPU
import torch
print(f"\n{'âœ…' if torch.cuda.is_available() else 'âš ï¸'} GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No disponible'}")
```

### 3ï¸âƒ£ Celda 2: Entrenar
```python
!python acepten_colab.py
```

### 4ï¸âƒ£ Celda 3: Descargar Resultados
```python
from google.colab import files
files.download('best_model.pt')
files.download('dataset_generated.csv')
files.download('training_history.png')
```

â±ï¸ **Tiempo total**: ~20-25 minutos en GPU T4

---

## ğŸ—ï¸ Arquitectura del Modelo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  Cadena (e.g., "ABC")    AFD (dfa_id=0)        â”‚
â”‚        â†“                      â†“                 â”‚
â”‚   TokenizaciÃ³n          Matriz 16Ã—12Ã—16         â”‚
â”‚    [0,1,2]              + Accept Vec            â”‚
â”‚        â†“                      â†“                 â”‚
â”‚   Embedding              MLP Encoder            â”‚
â”‚        â†“                      â†“                 â”‚
â”‚  BiGRU (2 capas)          h_afd (128)           â”‚
â”‚        â†“                                        â”‚
â”‚   h_str (128)                                   â”‚
â”‚        â”‚                      â”‚                 â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚        â”‚          â”‚                             â”‚
â”‚        â”‚     concat(h_str, h_afd)               â”‚
â”‚        â”‚          â”‚                             â”‚
â”‚        â”‚      â”Œâ”€â”€â”€â”´â”€â”€â”€â”                         â”‚
â”‚        â”‚      â”‚  MLP  â”‚                         â”‚
â”‚        â”‚      â””â”€â”€â”€â”¬â”€â”€â”€â”˜                         â”‚
â”‚        â”‚          â”‚                             â”‚
â”‚        â”‚     y1: Pertenencia                    â”‚
â”‚        â”‚     (Â¿acepta este AFD?)                â”‚
â”‚        â”‚                                        â”‚
â”‚     â”Œâ”€â”€â”´â”€â”€â”                                     â”‚
â”‚     â”‚ MLP â”‚                                     â”‚
â”‚     â””â”€â”€â”¬â”€â”€â”˜                                     â”‚
â”‚        â”‚                                        â”‚
â”‚   y2: Compartida                                â”‚
â”‚   (Â¿mÃºltiples AFDs?)                            â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total parÃ¡metros: ~1.9M
```

---

## ğŸ“Š Datos y Entrenamiento

### Dataset Generado
- **Entrada**: 6000 AFDs
- **Salida**: ~250K ejemplos
  - 30 positivos + 30 negativos por AFD
  - ~74% son cadenas compartidas (y2=1)

### Split
- **Train**: 70% (4200 AFDs)
- **Val**: 15% (900 AFDs)
- **Test**: 15% (900 AFDs)

### HiperparÃ¡metros
- **Optimizer**: Adam (lr=0.001)
- **Loss**: Î»â‚Â·BCE(y1) + Î»â‚‚Â·BCE(y2)
- **Batch size**: 128 (GPU) / 64 (CPU)
- **Ã‰pocas**: 30
- **RegularizaciÃ³n**: Dropout (0.2-0.3) + Weight Decay

---

## ğŸ¯ MÃ©tricas de Ã‰xito

### Tarea 1: Pertenencia a AFD (y1)
| Nivel | Accuracy | F1 Score |
|-------|----------|----------|
| ğŸ¥‡ Muy Bueno | â‰¥ 0.95 | â‰¥ 0.95 |
| ğŸ¥ˆ Bueno | 0.90-0.95 | 0.90-0.95 |
| ğŸ¥‰ Regular | 0.85-0.90 | 0.85-0.90 |
| âŒ Malo | < 0.85 | < 0.85 |

### Tarea 2: Cadena Compartida (y2)
| Nivel | F1 Score | PR-AUC |
|-------|----------|--------|
| ğŸ¥‡ Bueno | â‰¥ 0.90 | â‰¥ 0.90 |
| ğŸ¥ˆ Regular | 0.80-0.90 | 0.80-0.90 |
| âŒ Malo | < 0.80 | < 0.80 |

---

## ğŸ“¦ Salidas del Modelo

DespuÃ©s del entrenamiento, obtendrÃ¡s:

1. **`best_model.pt`** - Mejor modelo guardado (pesos)
2. **`dataset_generated.csv`** - Dataset completo con y1 e y2
3. **`training_history.png`** - GrÃ¡ficas de:
   - Loss (train/val)
   - Accuracy Y1 (train/val)
   - Accuracy Y2 (train/val)

---

## ğŸ”§ PersonalizaciÃ³n

### Cambiar nÃºmero de Ã©pocas
En `acepten_colab.py`, lÃ­nea 743:
```python
trainer.train(num_epochs=50)  # default: 30
```

### MÃ¡s datos por AFD
LÃ­nea 713:
```python
df = generator.generate_full_dataset(
    pos_samples_per_dfa=50,  # default: 30
    neg_samples_per_dfa=50   # default: 30
)
```

### Ajustar batch size
LÃ­nea 734:
```python
batch_size = 256  # default: 128 para GPU
```

---

## ğŸ’¡ CaracterÃ­sticas Principales

âœ… **Dual-Encoder Architecture**
- String encoder: BiGRU sobre tokens
- AFD encoder: MLP sobre matriz de transiciones

âœ… **Multi-Task Learning**
- Head 1: Pertenencia (usa string + AFD)
- Head 2: AmbigÃ¼edad (usa solo string)

âœ… **GeneralizaciÃ³n**
- Split por dfa_id â†’ evalÃºa en AFDs nunca vistos

âœ… **Manejo de Casos Especiales**
- Cadenas vacÃ­as (Ã©psilon)
- Secuencias de longitud variable
- Alfabetos distintos por AFD

âœ… **Optimizado para GPU**
- Batch processing eficiente
- Pin memory para transferencias rÃ¡pidas
- Mixed precision ready

---

## ğŸ“ PrÃ³ximos Pasos

### DespuÃ©s del Entrenamiento

1. **Analizar resultados**
   - Revisar `training_history.png`
   - Verificar mÃ©tricas en test set

2. **Experimentos**
   - Cambiar arquitectura (mÃ¡s capas, GNN)
   - Data augmentation
   - Diferentes splits

3. **Deployment**
   - Cargar modelo: `torch.load('best_model.pt')`
   - Inferencia en nuevos AFDs

### Ejemplo de Inferencia

```python
# Cargar modelo
model = DualEncoderModel()
model.load_state_dict(torch.load('best_model.pt'))
model.eval()

# Preparar input
parser = AFDParser('dataset6000.csv')
afd_features = parser.get_afd_features(dfa_id=0)
string_tokens = [0, 1, 2]  # "ABC"

# Predecir
with torch.no_grad():
    y1_hat, y2_hat = model(...)
    print(f"Pertenece: {y1_hat > 0.5}")
    print(f"Compartida: {y2_hat > 0.5}")
```

---

## ğŸ“ Referencias

Este proyecto implementa las ideas de tu plan original:
- Parseo de AFDs desde dataset estructurado
- RepresentaciÃ³n vectorial con one-hot encoding
- Arquitectura dual-encoder con multi-task learning
- EvaluaciÃ³n rigurosa con mÃ©tricas claras

**CaracterÃ­sticas implementadas exactamente como especificaste**:
- âœ… Alfabeto global A-L (12 sÃ­mbolos)
- âœ… Max 16 estados (S0-S15)
- âœ… Matriz de transiciones 16Ã—12Ã—16
- âœ… Two-head architecture
- âœ… y2 basado en conteo de AFDs por string
- âœ… Split por dfa_id (no por strings)

---

## ğŸ™Œ Â¡Todo Listo!

Tienes todo lo necesario para entrenar el modelo. Sube los archivos a Colab y Â¡a entrenar! ğŸš€

**Archivos que necesitas subir a Colab**:
1. `dataset6000.csv`
2. `acepten_colab.py`

Â¡Ã‰xito con el entrenamiento! ğŸ‰

