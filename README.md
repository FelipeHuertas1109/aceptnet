# ğŸ¤– Modelo Dual-Encoder para ClasificaciÃ³n de Cadenas en AFDs

Modelo multi-tarea basado en deep learning que aprende a:
1. **Determinar si una cadena pertenece a un autÃ³mata especÃ­fico**
2. **Predecir si una cadena puede ser aceptada por mÃºltiples autÃ³matas**

## ğŸ—ï¸ Arquitectura

El modelo utiliza una arquitectura **dual-encoder** con dos cabezas de salida:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  Cadena (string)        AFD (AutÃ³mata)                     â”‚
â”‚       â†“                       â†“                             â”‚
â”‚  Embedding              Matriz de                           â”‚
â”‚       â†“                 Transiciones                        â”‚
â”‚  BiGRU (2 capas)             â†“                              â”‚
â”‚       â†“                   MLP                               â”‚
â”‚    h_str                    â†“                               â”‚
â”‚       â”‚                  h_afd                              â”‚
â”‚       â”‚                     â”‚                               â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚       â”‚         â”‚                                           â”‚
â”‚       â”‚    concat(h_str, h_afd)                             â”‚
â”‚       â”‚         â”‚                                           â”‚
â”‚       â”‚      â”Œâ”€â”€â”´â”€â”€â”                                        â”‚
â”‚       â”‚      â”‚ MLP â”‚                                        â”‚
â”‚       â”‚      â””â”€â”€â”¬â”€â”€â”˜                                        â”‚
â”‚       â”‚         â”‚                                           â”‚
â”‚       â”‚    y1: Â¿Pertenece a este AFD?                       â”‚
â”‚       â”‚                                                     â”‚
â”‚    â”Œâ”€â”€â”´â”€â”€â”                                                  â”‚
â”‚    â”‚ MLP â”‚                                                  â”‚
â”‚    â””â”€â”€â”¬â”€â”€â”˜                                                  â”‚
â”‚       â”‚                                                     â”‚
â”‚  y2: Â¿Cadena compartida con otros AFDs?                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Clave

1. **String Encoder**: 
   - Embedding de sÃ­mbolos (A-L)
   - BiGRU bidireccional de 2 capas
   - Captura patrones secuenciales en las cadenas

2. **AFD Encoder**:
   - MLP de 3 capas
   - Entrada: representaciÃ³n vectorial del AFD (3104 dims)
     - Matriz de transiciones one-hot: 16 Ã— 12 Ã— 16
     - Vector de estados de aceptaciÃ³n: 16
     - MÃ¡scara de estados vÃ¡lidos: 16

3. **Multi-Task Heads**:
   - **Head 1** (pertenencia): combina informaciÃ³n de cadena + AFD
   - **Head 2** (compartida): usa solo informaciÃ³n de la cadena

## ğŸ“Š Datos

### Entrada: `dataset6000.csv`
Contiene 6000 autÃ³matas con:
- Regex
- Alfabeto
- Estados y estados de aceptaciÃ³n
- Transiciones
- Clase (cadenas aceptadas/rechazadas)

### GeneraciÃ³n AutomÃ¡tica
El script genera automÃ¡ticamente pares `(dfa_id, string, label)`:
- **Positivos**: extraÃ­dos de la columna `Clase` (cadenas aceptadas)
- **Negativos**: generados aleatoriamente y verificados por simulaciÃ³n

### Labels
- **y1**: Â¿La cadena pertenece a este AFD? (0 o 1)
- **y2**: Â¿La cadena es aceptada por â‰¥2 AFDs diferentes? (0 o 1)

## ğŸš€ Uso

### InstalaciÃ³n

```bash
pip install -r requirements.txt
```

### Entrenamiento

```bash
python acepten.py
```

El script ejecuta el pipeline completo:
1. âœ… Carga y parsea los 6000 AFDs
2. âœ… Genera dataset de pares (dfa_id, string, label)
3. âœ… Calcula etiqueta y2 (cadenas compartidas)
4. âœ… Divide en train/val/test por dfa_id (70/15/15)
5. âœ… Entrena el modelo dual-encoder
6. âœ… EvalÃºa en test set
7. âœ… Genera visualizaciones

### Salidas

- `dataset_generated.csv`: Dataset completo generado
- `best_model.pt`: Mejor modelo entrenado
- `training_history.png`: GrÃ¡ficas de entrenamiento

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

### Tarea 1: Pertenencia a AFD (y1)

| MÃ©trica | Muy Bueno | Bueno | Regular | Malo |
|---------|-----------|-------|---------|------|
| **Accuracy** | â‰¥ 0.95 | 0.90-0.95 | 0.85-0.90 | < 0.85 |
| **F1 Score** | â‰¥ 0.95 | 0.90-0.95 | 0.85-0.90 | < 0.85 |

### Tarea 2: Cadena Compartida (y2)

| MÃ©trica | Bueno | Regular | Malo |
|---------|-------|---------|------|
| **F1 Score** | â‰¥ 0.90 | 0.80-0.90 | < 0.80 |
| **PR-AUC** | â‰¥ 0.90 | 0.80-0.90 | < 0.80 |

## ğŸ”§ ConfiguraciÃ³n

Puedes ajustar hiperparÃ¡metros en la funciÃ³n `main()`:

```python
# GeneraciÃ³n de datos
generator.generate_full_dataset(
    pos_samples_per_dfa=30,  # Muestras positivas por AFD
    neg_samples_per_dfa=30   # Muestras negativas por AFD
)

# Entrenamiento
trainer = Trainer(
    model, 
    train_loader, 
    val_loader,
    lambda1=1.0,    # Peso de loss y1
    lambda2=1.0,    # Peso de loss y2
    lr=0.001,       # Learning rate
    device=device
)
trainer.train(num_epochs=30)
```

## ğŸ¯ GeneralizaciÃ³n a AutÃ³matas Nuevos

El split por `dfa_id` asegura que el modelo aprende patrones generales de autÃ³matas, no memoriza autÃ³matas especÃ­ficos. Los AFDs en test nunca se vieron durante el entrenamiento.

## ğŸ§ª Extensiones Posibles

1. **GNN para AFDs**: Reemplazar MLP con Graph Neural Network
2. **Attention Mechanism**: Agregar atenciÃ³n entre string y AFD
3. **Data Augmentation**: Generar mÃ¡s cadenas usando regex
4. **Transfer Learning**: Pre-entrenar en lenguajes formales
5. **Multi-length Analysis**: Evaluar por longitud de cadena

## ğŸ“ Notas TÃ©cnicas

- **Alfabeto global**: A, B, C, D, E, F, G, H, I, J, K, L (12 sÃ­mbolos)
- **Max estados**: 16 (S0-S15)
- **Padding**: Secuencias variables con pad_idx=12
- **Device**: Auto-detecta CUDA/CPU
- **OptimizaciÃ³n**: Adam + ReduceLROnPlateau
- **RegularizaciÃ³n**: Dropout (0.2-0.3) + Weight Decay

## ğŸ“„ Licencia

Este proyecto es parte de un experimento de investigaciÃ³n en aprendizaje automÃ¡tico aplicado a teorÃ­a de autÃ³matas.

